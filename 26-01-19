### Urban Camera Network Calibration with Satellite Images – 연구 절차 중심 흐름

- **문제 정의 :**
    - 기존 도시 CCTV 네트워크에서의 카메라 보정은 복잡한 환경과 제한된 이미지로 인해 어려우며,
    - 다수의 사전 설치된 카메라를 체스보드 없이 보정할 필요가 있다.
    - 카메라 사양과 각 카메라별 한 장의 영상만으로 도시 환경의 CCTV 카메라들을 보정하는 시스템을 제안한 논문이다.
- **방법 설계**
    - 제안 방법은 다음 네 가지 핵심 아이디어로 구성 :
        - (1) **위성 영상 활용 :** CCTV 카메라 및 도로 표식(마커)의 절대 3D 좌표를 추정하여 초기 위치를 얻는다.
        - (2) **복수 카메라 모델 도입 :** 카메라별 시야각 차이를 반영하기 위해 여러 종류의 투영 모델(예: 일반 투영, FOV 왜곡 포함 모델 등)을 고려한다.
        - (3) **지형 모델 사용 :** 평지, 언덕, 계단 등 여러 도시 지형 변화를 표현하는 지형 모델을 도입하여 X/Y 방향 이동이나 Z축 변위 등을 모델링.
        - (4) **교차 검증 기반 모델 선택 :** 훈련/검증 RMSE와 과적합 지표를 계산하여 각 모델 조합의 일반화 성능을 평가하고 최적 모델을 선택.
- **실험 및 평가**
    - 제안 시스템은 가상 환경과 실제 환경에서 평가되었다.
    - 가상 실험에서는 세 가지 지형(평지, 언덕, 계단)을 설정하여 각 카메라/지형 모델 조합의 성능을 비교.
    - 이때 최적의 모델 조합은 실제 생성 모델(Ground Truth)을 포함하며, 전체 4대 카메라의 평균 RMSE가 24.325에서 0.5–21.817로 크게 감소하는 효과를 보임.
    - 실제 환경에서는 ETRI 연구소의 4대 CCTV를 대상으로 보정 실험을 수행하여, 모델 선택 지표로 선별한 모델들의 왜곡 보정 결과를 질적으로 평가.
    - 최종적으로 제안 모델로 보정한 영상들은 기존에 비해 왜곡이 현저히 줄어든 것을 확인함.

### Urban Camera Network Calibration with Satellite Images – 이론 및 개념 전개 중심 흐름

- **기초 개념**
    - 본 연구는 도시 환경의 CCTV 네트워크를 캘리브레이션하기 위해 여러 카메라와 지면 요소를 동시에 고려한다.
    - 이를 위해 각 카메라의 내부/외부 파라미터 추정 개념(단일 카메라 캘리브레이션)에서 출발하여,
    - 서로 다른 위치의 카메라들이 공유하는 도로 표식(마커)을 활용하는 네트워크 보정 개념으로 확장한다.
    - 위성 이미지로 얻은 도로 표식의 3D 좌표는 네트워크 캘리브레이션의 초기 입력값으로 사용.
- **모델 정의**
    - 논문에서는 **여러 종류의 카메라 모델**과 **지형 모델**을 정의
    - 표준 핀홀 투영 모델(Perspective Projection), 넓은 시야각을 갖는 CCTV에 적합한 FOV 왜곡 모델(Field-of-View Model) 등 을 도입.
    - 지형 모델은 X, Y 방향 이동과 Z 방향 높이 변화(언덕, 계단 등)를 나타내며, 각 경우를 수평(X̄, Ȳ) 또는 기울기(θ) 포함 여부로 구분한다.
    - 위성 영상을 통해 얻은 도로 표식 좌표는 이러한 모델의 초기 조건으로 사용된다.
- **알고리즘 설명**
    - 모델 학습은 SciPy 라이브러리의 비선형 최소 제곱(Trust Region Reflective)으로 수행된다.
    - 목적 함수는 카메라 모델과 지형 모델 파라미터를 포함하며, 각 CCTV 영상에 찍힌 도로 표식의 위치와 이론적 투영위치 간의 오차를 최소화한다.
    - 학습 과정에서 전체 데이터의 일부를 검증용으로 나누어 사용하며, 훈련/검증 RMSE를 계산하여 과적합 정도를 평가한다.
    - 이 값들로 계산된 모델 선택 지표를 통해 가장 타당한 카메라 모델·지형 모델 조합을 결정한다.
    - 최종적으로 선택된 모델은 각 카메라의 내부/외부 파라미터를 제공하며, 이를 통해 왜곡 보정 및 3D 공간상의 카메라 위치 시각화를 수행한다.

### 카메라 캘리브레이션의 원리와 기술 동향 – 연구 절차 중심 흐름

- **문제 정의**
    - 카메라 캘리브레이션
        - 실제 카메라로 촬영한 이미지와 그에 대응하는 3차원 점 정보를 이용해 카메라의 내부(intrinsic) 및 외부(extrinsic) 파라미터를 추정하는 과정
        - 이러한 과정은 카메라 행렬과 렌즈 왜곡 계수, 카메라 자세 등을 찾아내어 3D-2D 투영 모델을 완성하는 것을 의미
- **방법 설계**
    - 캘리브레이션은 주로 2 단계로 나누어 수행
        - 전단계(front-end) : 체스보드 등 패턴 마커의 교차점과 같은 특징점을 검출하여 3차원 좌표와 이미지상의 대응점을 확보한다.
        - 후단계(back-end) : 확보된 대응점을 이용해 카메라 파라미터를 계산한다.
            - **1)** 왜곡을 무시한 간단한 모델로 닫힌 형식 해를 구하고,
            - **2)** 그 결과를 초기값으로 사용하여 Levenberg–Marquardt 등의 비선형 최적화로 재투영 오차를 최소화하며 파라미터를 정밀화한다.
- **대표적 방법 (Zhang’s Method)**
    - Zhang 방법은 평면 패턴(체스보드)에서 얻은 여러 이미지로 캘리브레이션을 수행한다.
    - 우선 평면 호모그래피를 이용해 내부/외부 파라미터의 초기 추정값을 닫힌 형식으로 계산하고,
    - 이후 재투영 오차를 비용함수로 한 비선형 최적화를 통해 최적의 파라미터를 찾는다.
    - 이 과정에서 OpenCV 카메라 캘리브레이션 함수는 RMS 오차 값을 출력하며, 이 값을 통해 결과 일관성을 평가할 수 있다.
- **실험 및 평가**
    - 일반적으로 캘리브레이션 결과의 정확도는 재투영 RMS 오차로 평가한다.
    - 캘리브레이션 시에는 패턴을 다양한 각도로 기울여 소실점이 생기도록 촬영하는 것이 바람직하며,
    - (예를 들어 체스보드를 너무 똑바로 촬영하기보다는 약간 기울이는 것이 좋다) 오토포커스는 꺼서 초점거리가 고정되도록 한다.

### 카메라 캘리브레이션의 원리와 기술 동향 – 이론 및 개념 전개 중심 흐름

- **기초 개념**
    - 카메라는 3차원 공간의 점 X를 2차원 영상평면의 점 x로 투영한다.
    - 수학적으로 이상적인 핀홀 모델에서는 x = K [ R∣t ] X로 표현되며,
    - 여기서 K는 카메라 행렬(camera matrix)로 내부 파라미터(초점거리, 주점, skew 등)를 포함한다.
    - 외부 파라미터 R, t는 카메라의 회전과 이동을 나타내며 이 둘을 합쳐 카메라의 pose를 정의한다.
- **모델 정의**
    - 카메라 행렬 K는 다음과 같은 형태의 3×3 행렬이다 :
    
    $$
    K = \begin{bmatrix} f_x & s & c_x \\ 0 & f_y & c_y \\ 0 & 0 & 1 \end{bmatrix}
    $$
    
    - 여기서 f_x, f_y는 각 축 방향 초점거리, c_x, c_y는 주점, s는 축 사이 기울기이다.
    - 이 행렬과 외부 파라미터 R, t 추가적으로 렌즈의 기하학적 왜곡 계수(k1,k2,…)를 합하여 카메라 투영 모델을 완성한다.
    - 렌즈 왜곡은 주로 다항식 또는 FOV 모델로 근사한다.
- **알고리즘 설명**
    - Zhang’s 방법 등에서는 3차원 평면 위의 마커 패턴 대응점을 이용한다.
    - 우선 평면(z=0) 호모그래피를 계산하여 내부/외부 파라미터의 초기 해를 closed-form으로 얻고,
    - 그 결과를 초기값으로 하여 Levenberg–Marquardt 최적화를 수행한다.
    - 이때 비용함수는 검출점과 재투영점 간의 유클리드 거리로 정의되며, 이를 최소화하여 최종 파라미터를 결정한다.
    - 이러한 방식은 Structure-from-Motion의 번들 조정과 유사하게 작동하나, 이 경우 3D 점의 위치는 고정된다는 점이 차이점이다.
